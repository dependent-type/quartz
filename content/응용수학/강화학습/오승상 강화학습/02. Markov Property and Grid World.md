# Grid world example
강화학습을 통해 스스로 학습하는 주체를 **Agent** 라고 한다. **Grid World Model**은 강화학습을 설명할 수 있는 간단한 모델 중 하나로, agent가 $m \times n$ 격자 칸에서 인접한 격자로 움직이되 바깥으로 나가지 않는 것이 규칙이다.

## Grid World Model
Grid world에서는 강화학습의 변수가 어떻게 정의될까? 우선, 무언가의 학습을 시키려면 현재의 **상태(State)** 와 취하는 **행동(Action)** 에 대한 데이터가 필요할 것이다. 예를 들어 아래와 같은 상황을 가정하여 보자.
![[스크린샷 2023-08-05 오후 1.50.06.png|500x400]]

이와 같은 $4 \times 3$ 그리드가 모든 일들이 벌어지는 이 강화학습의 **세상**이고, 따라서 Agent의 상태를 대변하는 변수, **State** $S$는 다음과 같이 정의할 수 있을 것이다.
$$
S = \{ (1,1),(1,2),(1,3),\ldots,(4,2),(4,3) \}
$$

마찬가지로, Agent가 취할 수 있는 행동 **Action** $A$ 또한 아래와 같이 정의할 수 있다.
$$
A = \{ \mathrm{north,south,east,west}\}
$$

위 그림의 상황에서의 보상 **Reward**는 1 또는 -1의 큰 값이다. 하지만 꼭 그것만 있는 것은 아니고, 지나치게 [와리가리](https://www.youtube.com/watch?v=ECMc1SB60E0&pp=ygUM7JmA66as6rCA66as)하는 것을 방지하기 위해 한번의 시행마다 작은 음의 보상 $c$를 주기도 한다.

또한, Agent가 굳이 선택한 Action대로 움직일 필요도 없다. 이는 [[2.1 An n-Armed Bandit Problem#^efbc75|n-Armed Bandit Problem]]에서 유사한 내용인 **exploring**과 **exploiting**에 대해서 다룬 바 있으니 참고하길 바란다. 확률적으로 다른 선택을 함으로서 더 Optimal한 결과를 얻을 수 있기 때문이다. 예를 들어, $A$에서 $\mathrm{north}$를 택한다면 실제로는 80%의 확률로 북쪽으로 가고, 각각 10%의 확률로 동쪽 또는 서쪽으로 이동하는 **노이즈**를 줄 수 있다.


## Actions in Grid World

![[스크린샷 2023-08-05 오후 2.40.19.png|500x300]]
위에서 설명했듯이, 결정한 선택을 그대로 따르는 grid world를 **Deterministic(결정론적)**, 약간의 무작위성을 추가한 것을 **Stochastic(확률론적)** grid world라고 한다.

